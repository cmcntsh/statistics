---
title: "Simulating Variables (nominal, ordinal, interval, ratio, factors w/ outcome, correlated)"
output: html_notebook
---
Nice tutorial on simulating data: https://aosmith.rbind.io/2018/08/29/getting-started-simulating-data/
simstudy documentation: https://cran.r-project.org/web/packages/simstudy/vignettes/simstudy.html
https://clayford.github.io/dwir/dwr_12_generating_data.html
Simulate from regression model: https://stats.stackexchange.com/questions/115748/simulate-data-for-2-x-2-anova-with-interaction
Complex example: https://stats.idre.ucla.edu/r/codefragments/mesimulation/
https://rpubs.com/hughrab/lab8
simulate dataset with relationships between variables: https://gist.github.com/DASpringate/7804997
```{r}
# List the packages needed
packages <- c("tidyverse","summarytools", "simstudy", "OrdNor", "copula", "rio")

# Check if each package is installed already. If not, install the package.
for (i in packages){
  if(! i %in% installed.packages()){
    install.packages(i,dependencies = TRUE)
  }
  # Show each package that is checked.
  print(i)
  
  # Load each package into memory so we can use it.
  library(i,character.only=TRUE)
}

```

```{r}
# simulating nominal data

# set number of participants
n = 40

# generate data
A = c(rep(c("male"), n/2), rep(c("female"), n/2)) # '0' n/2 times, '1' n/2 times

# add to dataframe
df = data.frame(cbind(A))

# check it out
class(df$A)
df$A
```

```{r}
# simulate nominal data using simstudy package
library(simstudy)

#### number of observations
n = 30

#### Set definitions

def1 <- defData(varname = "male", formula = 0.45, dist = "binary", id = "idG")
def1 <- defData(def1, varname = "z", formula = "1.2*male", dist = "nonrandom")

#### Generate data

set.seed(20)

dx <- genData(n, def1)

probs<-c(0.40, 0.25, 0.15)
dx <- genOrdCat(dx, adjVar = "z", probs, catVar = "grp")
View(dx)
```


```{r}
# smulating ordinal data

# set number of participants
n = 30

# list of category names
names = list("uno", "due", "tre")

# generate data
B = c(rep(c(paste(names[1])), n/3), rep(c(paste(names[2])), n/3), rep(c(paste(names[3])), n/3)) # '0' n/3 times, '1' n/3 times, '2' n/3 times

# add to dataframe
df = data.frame(cbind(B))

# order the factors to be the same as the original list
df$B <- ordered(df$B, levels = c(paste(names[1]), paste(names[2]), paste(names[3])))

# check it out
class(df$B)
df$B
```
```{r}
# simulate correlated ordinal variables
set.seed(8649)     # this makes the example exactly reproducible
N      = n        # this is how much data I'll generate
latent = rnorm(N)  # this is the actual latent variable I want to be measureing

##### generate latent responses to items
df$item1 = latent + rnorm(N, mean=0, sd=0.2)  # the strongest correlate
df$item2 = latent + rnorm(N, mean=0, sd=0.3)
df$item3 = latent + rnorm(N, mean=0, sd=0.5)
df$item4 = latent + rnorm(N, mean=0, sd=1.0)
df$item5 = latent + rnorm(N, mean=0, sd=1.2)  # the weakest

##### convert latent responses to ordered categories
df$item1 = findInterval(df$item1, vec=c(-Inf,-2.5,-1, 1,2.5,Inf))  # fairly unbiased
df$item2 = findInterval(df$item2, vec=c(-Inf,-2.5,-1, 1,2.5,Inf))
df$item3 = findInterval(df$item3, vec=c(-Inf,-3,  -2, 2,3,  Inf))  # middle values typical
df$item4 = findInterval(df$item4, vec=c(-Inf,-3,  -2, 2,3,  Inf))
df$item5 = findInterval(df$item5, vec=c(-Inf,-3.5,-3,-1,0.5,Inf))  # high ratings typical

##### combined into final scale
df$manifest = round(rowMeans(cbind(item1, item2, item3, item4, item5)), 1)
View(df)
```

```{r}
# simulate correlated ordinal and normal variables using OrdNor package

library(OrdNor)

Sigma = diag(4)
Sigma[lower.tri(Sigma)] = c(0.42, 0.78, 0.29, 0.37, 0.14, 0.26)
Sigma = Sigma + t(Sigma)
diag(Sigma)=1

marginal = list( c(0.2, 0.5), c(0.4, 0.7, 0.9))
cmat= cmat.star(marginal, Sigma, 2, 2)  
mean.vec = c(2,4)
sd.vec = c(0.5, 1.5)
Y=genOrdNor(30,marginal, cmat, mean.vec, sd.vec, 2, 2)
View(Y)
cor(Y)
```
```{r}
# R code to produce a simulated dataset for an experiment on a made up insect. 
# Measures include sex, body length, thorax width, number of thoracic bristles and some measure of aggression behaviour. 
# Also there is exposure to some treatment stimulus/drug. 
# This simulation uses Copulas to generate correlated variables from binomial, Gaussian and Poisson distributions

require(copula)

set.seed(1888)

n <- 1000 

# 6 variables:

# sex (binomial)
# length (Gaussian)
# treatment (binomial)
# Number of bristles on Thorax (Poisson)
# aggression (Stratified normal distribution)
# Thorax width (Gaussian)


## build a normal copula for the underlying distibution:
# `param` is the lower triangle of a correlation matrix
underlying <- normalCopula(dim = 6, 
                      param = c(-0.4,0,-0.2,-0.5,-0.2,   # sex
                                0.3,0.05,0.5,0.7,        # length
                                0.4,0.6,0.3,             # treatment
                                0.3,0.1,                 # bristles
                                0.5),                    # aggression
                      dispstr = "un") # The Copula

# distribution which can be used for margins
# https://www.stat.umn.edu/geyer/old/5101/rlook.html
# https://stat.ethz.ch/R-manual/R-patched/library/stats/html/Distributions.html
# beta, binom, cauchy, chisq, exp, f, gamma, geom, hyper, logis, lnorm, nbinom, norm, pois, t, tukey, unif, weibull, wilcox, signrank

## build the marginal distibutions from the underlying copula
marginals <- mvdc(copula = underlying, 
                  margins = c("binom", "norm", "binom", "pois", "norm", "norm"), 
                  paramMargins = list(list(size = 1, prob = 0.5), # parameters for the marginal distributions...
                                      list(mean = 30, sd = 13),
                                      list(size = 1, prob = 0.5),
                                      list( lambda = 5),
                                      list(mean = 0, sd = 1),
                                      list(mean = 20, sd = 4))) 

## generate the correlated random variables from the marginal distributions
dat <- as.data.frame(rMvdc(n, marginals)) 

## rename the variables
names(dat) <- c("sex", "length", "treatment", "bristles", "agg_base", "width")

## Stratify the aggression variable
dat$aggression <- cut(round(dat$agg_base, 5),
                      seq(from=min(dat$agg_base), to = max(dat$agg_base),length.out = 6))

levels(dat$aggression) <- paste0("aggress_",1:5)

# convert others to factors and clean up
dat$aggression <- ordered(dat$aggression)
dat$sex <- factor(dat$sex)
levels(dat$sex) <- c("Male", "Female")
dat$treatment <- factor(dat$treatment)
levels(dat$treatment) <- c("Control", "Treatment")
dat$agg_base <- NULL
dat <- dat[complete.cases(dat),]
```
```{r}
view(dfSummary(dat))
rio::export(dat,file = "insect.sav")
```
```{r}
# modification of code block above 

# R code to produce a simulated dataset for an experiment on a made up insect. 
# Measures include sex, body length, thorax width, number of thoracic bristles and some measure of aggression behaviour. 
# Also there is exposure to some treatment stimulus/drug. 
# This simulation uses Copulas to generate correlated variables from binomial, Gaussian and Poisson distributions

require(copula)

set.seed(1888)

n <- 100 

# 6 variables:

# sex (binomial)
# length (Gaussian)
# treatment (binomial)
# Number of bristles on Thorax (Poisson)
# aggression (Stratified normal distribution)
# Thorax width (Gaussian)

# 11 new variables
# sex (binomial)
# research (binomial)
# height (Gaussian)
# weight (Gaussian)
# lvst1 (Gaussian)
# lvst2 (Gaussian)
# lvst3 (Gaussian)
# lvst4 (Gaussian)
# frst1 (Gaussian)
# frst2 (Gaussian)
# frst3 (Gaussian)


underlying <- normalCopula(dim = 11,
                           param = c(
0.3,-0.5,-0.5,0.3,0.2,0.3,-0.4,-0.3,-0.4,-0.1,    # sex
0.05,0.1,0.3,0.3,0.3,-0.4,-0.3,-0.4,-0.3,     # research
0.8,0.1,0.1,0.1,0.1,0.1,0.1,0.1,      # height
0.1,0.1,0.2,-0.2,-0.2,-0.1,-0.1,       # weight
0.6,0.7,0.8,-0.7,-0.6,-0.5,        # lvst1
0.6,-0.6,-0.6,-0.6,-0.7,         # lvst2
-0.5,-0.5,-0.5,-0.6,          # lvst3
0.4,0.5,0.6,           # lvst4
0.6,0.7,            # frst1
0.6),              # frst2
dispstr = "un")

marginals <- mvdc(copula = underlying,
                  margins = c("binom", "binom","norm","norm","norm","norm",
                              "norm","norm","norm","norm","norm"),
                  paramMargins = list(list(size = 1, prob = 0.5),
                                      list(size = 1, prob = 0.5),
                                      list(mean = 160, sd = 20),
                                      list(mean = 68, sd = 20),
                                      list(mean = 4.5, sd = 1),
                                      list(mean = 5, sd = 1),
                                      list(mean = 4.8, sd = 1),
                                      list(mean = 1.2, sd = 2),
                                      list(mean = 2, sd = 1),
                                      list(mean = 2.3, sd = 1),
                                      list(mean = 1.5, sd = 1)))

## build a normal copula for the underlying distibution:
# `param` is the lower triangle of a correlation matrix
#underlying <- normalCopula(dim = 6, 
#                      param = c(-0.4,0,-0.2,-0.5,-0.2,   # sex
#                                0.3,0.05,0.5,0.7,        # length
#                                0.4,0.6,0.3,             # treatment
#                                0.3,0.1,                 # bristles
#                                0.5),                    # aggression
#                      dispstr = "un") # The Copula

# distribution which can be used for margins
# https://www.stat.umn.edu/geyer/old/5101/rlook.html
# https://stat.ethz.ch/R-manual/R-patched/library/stats/html/Distributions.html
# beta, binom, cauchy, chisq, exp, f, gamma, geom, hyper, logis, lnorm, nbinom, norm, pois, t, tukey, unif, weibull, wilcox, signrank

## build the marginal distibutions from the underlying copula
#marginals <- mvdc(copula = underlying, 
#                  margins = c("binom", "norm", "binom", "pois", "norm", "norm"), 
#                  paramMargins = list(list(size = 1, prob = 0.5), # parameters for the marginal distributions...
#                                      list(mean = 30, sd = 13),
#                                      list(size = 1, prob = 0.5),
#                                      list( lambda = 5),
#                                      list(mean = 0, sd = 1),
#                                      list(mean = 20, sd = 4))) 

## generate the correlated random variables from the marginal distributions
dat <- as.data.frame(rMvdc(n, marginals)) 

## rename the variables
#names(dat) <- c("sex", "length", "treatment", "bristles", "agg_base", "width")

names(dat) <- c("sex", "research", "height", "weight", "lvst1_base", "lvst2_base",
                "lvst3_base","lvst4_base","frst1_base","frst2_base","frst3_base")

## round continuous variables
dat$height <- round(dat$height,1)
dat$weight <- round(dat$weight,1)

## Stratify the aggression variable
dat$lvst1 <- cut(round(dat$lvst1_base, 5),
                      seq(from=min(dat$lvst1_base),
                          to = max(dat$lvst1_base),length.out = 6))
dat$lvst2 <- cut(round(dat$lvst2_base, 5),
                      seq(from=min(dat$lvst2_base),
                          to = max(dat$lvst2_base),length.out = 6))
dat$lvst3 <- cut(round(dat$lvst3_base, 5),
                      seq(from=min(dat$lvst3_base),
                          to = max(dat$lvst3_base),length.out = 6))
dat$lvst4 <- cut(round(dat$lvst4_base, 5),
                      seq(from=min(dat$lvst4_base),
                          to = max(dat$lvst4_base),length.out = 6))
dat$frst1 <- cut(round(dat$frst1_base, 5),
                      seq(from=min(dat$frst1_base),
                          to = max(dat$frst1_base),length.out = 6))
dat$frst2 <- cut(round(dat$frst2_base, 5),
                      seq(from=min(dat$frst2_base),
                          to = max(dat$frst2_base),length.out = 6))
dat$frst3 <- cut(round(dat$frst3_base, 5),
                      seq(from=min(dat$frst3_base),
                          to = max(dat$frst3_base),length.out = 6))

levels(dat$lvst1) <- paste0("lovest_",1:5)
levels(dat$lvst2) <- paste0("lovest_",1:5)
levels(dat$lvst3) <- paste0("lovest_",1:5)
levels(dat$lvst4) <- paste0("lovest_",1:5)
levels(dat$frst1) <- paste0("fearst_",1:5)
levels(dat$frst2) <- paste0("fearst_",1:5)
levels(dat$frst3) <- paste0("fearst_",1:5)

levels(dat$lvst1) <- c("Not at all", "a little",
                       "moderately", "mostly", "completely")
levels(dat$lvst2) <- c("Not at all", "a little",
                       "moderately", "mostly", "completely")
levels(dat$lvst3) <- c("Not at all", "a little",
                       "moderately", "mostly", "completely")
levels(dat$lvst4) <- c("Not at all", "a little",
                       "moderately", "mostly", "completely")
levels(dat$frst1) <- c("Not at all", "a little",
                       "moderately", "mostly", "completely")
levels(dat$frst2) <- c("Not at all", "a little",
                       "moderately", "mostly", "completely")
levels(dat$frst3) <- c("Not at all", "a little",
                       "moderately", "mostly", "completely")

# convert others to factors and clean up
dat$lvst1 <- ordered(dat$lvst1)
dat$lvst2 <- ordered(dat$lvst2)
dat$lvst3 <- ordered(dat$lvst3)
dat$lvst4 <- ordered(dat$lvst4)
dat$frst1 <- ordered(dat$frst1)
dat$frst2 <- ordered(dat$frst2)
dat$frst3 <- ordered(dat$frst3)

dat$sex <- factor(dat$sex)
levels(dat$sex) <- c("Male", "Female")

dat$research <- factor(dat$research)
levels(dat$research) <- c("Quant", "Qual")

dat$lvst1_base <- NULL
dat$lvst2_base <- NULL
dat$lvst3_base <- NULL
dat$lvst4_base <- NULL
dat$frst1_base <- NULL
dat$frst2_base <- NULL
dat$frst3_base <- NULL

label(dat[["sex"]]) <- "Sex of participants."
label(dat[["research"]]) <- "Type of researcher."
label(dat[["height"]]) <- "Height in cm."
label(dat[["weight"]]) <- "Weight in kg."
label(dat[["lvst1"]]) <- "How much do you love statistics?"
label(dat[["lvst2"]]) <- "How much do you love data?"
label(dat[["lvst3"]]) <- "How much do you love analyzing data?"
label(dat[["lvst4"]]) <- "How much do you dislike data cleaning?"
label(dat[["frst1"]]) <- "How much do you fear statistics?"
label(dat[["frst2"]]) <- "How much do you distrust statistics?"
label(dat[["frst3"]]) <- "How much do you dislike science?"
```
```{r}
rio::export(dat,"week3.rds")
rio::export(dat,"week3.sav")
```

```{r}
attributes(dat)
attributes(dat$sex)
label(dat)
label(dat$sex)
view(dfSummary(dat))
```

```{r}
# simulating interval data

```

```{r}
# simulating ratio data
# This is done by running a regression in reverse. Could try without any predictors (just mean and error)
# simulate outcome with 1 predictor (1-way ANOVA)

# set total participants
n = 40

# Set coefficients
alpha = 66
beta1 = 1.5
sde = 2 # standard deviation of the errors (values 1-3 seems to work well)

# Generate 200 trials
A = c(rep(c(0), n/2), rep(c(1), n/2)) # '0' n/2 times, '1' n/2 times
e = rnorm(n, 0, sd=sde) # Random noise, with standard deviation of 1

# Generate your data using the regression equation
y = alpha + beta1*A + e

# Join the variables in a data frame
data = data.frame(cbind(A, y))

# Fit an ANOVA
modelA = aov(y ~ A, data=data)
summary(modelA)



```

```{r}
# simulate Likert-type data

x <- sample( LETTERS[1:4], 100, replace=TRUE, prob=c(0.1, 0.2, 0.65, 0.05) )
x
prop.table(table(x))
```

```{r}
# simulate Likert-type data measuring latent continuous variable

set.seed(8649)     # this makes the example exactly reproducible
N      = 10        # this is how much data I'll generate
latent = rnorm(N)  # this is the actual latent variable I want to be measureing

##### generate latent responses to items
item1 = latent + rnorm(N, mean=0, sd=0.2)  # the strongest correlate
item2 = latent + rnorm(N, mean=0, sd=0.3)
item3 = latent + rnorm(N, mean=0, sd=0.5)
item4 = latent + rnorm(N, mean=0, sd=1.0)
item5 = latent + rnorm(N, mean=0, sd=1.2)  # the weakest

##### convert latent responses to ordered categories
item1 = findInterval(item1, vec=c(-Inf,-2.5,-1, 1,2.5,Inf))  # fairly unbiased
item2 = findInterval(item2, vec=c(-Inf,-2.5,-1, 1,2.5,Inf))
item3 = findInterval(item3, vec=c(-Inf,-3,  -2, 2,3,  Inf))  # middle values typical
item4 = findInterval(item4, vec=c(-Inf,-3,  -2, 2,3,  Inf))
item5 = findInterval(item5, vec=c(-Inf,-3.5,-3,-1,0.5,Inf))  # high ratings typical

##### combined into final scale
manifest = round(rowMeans(cbind(item1, item2, item3, item4, item5)), 1)
manifest
cor(manifest, latent)
```


```{r}
# simulating correlated data

# this comes from https://stat.ethz.ch/pipermail/r-help/2007-April/128925.html

# create the initial x variable
x1 <- rnorm(100, 15, 5)

# x2, x3, and x4 in a matrix, these will be modified to meet the criteria
x234 <- scale(matrix( rnorm(300), ncol=3 ))

# put all into 1 matrix for simplicity
x1234 <- cbind(scale(x1),x234)

# find the current correlation matrix
c1 <- var(x1234)

# cholesky decomposition to get independence
chol1 <- solve(chol(c1))

newx <-  x1234 %*% chol1 

# check that we have independence and x1 unchanged
zapsmall(cor(newx))
all.equal( x1234[,1], newx[,1] )

# create new correlation structure (zeros can be replaced with other rvals)
newc <- matrix( 
c(1  , 0.4, 0.5, 0.6, 
  0.4, 1  , 0  , 0  ,
  0.5, 0  , 1  , 0  ,
  0.6, 0  , 0  , 1  ), ncol=4 )

# check that it is positive definite
eigen(newc)

chol2 <- chol(newc)

finalx <- newx %*% chol2 * sd(x1) + mean(x1)

# verify success
mean(x1)
colMeans(finalx)

sd(x1)
apply(finalx, 2, sd)

zapsmall(cor(finalx))
pairs(finalx)

all.equal(x1, finalx[,1])

xframe = as.data.frame(finalx)

```

```{r}
# left skewed
hist(rbeta(10000,5,2))
#or
x <- -rchisq(10000,6)
hist(x, breaks=40)
x <- x + abs(round(min(x),0))
hist(x, breaks=40)

# right skewed
hist(rbeta(10000,2,5))
#or
x <- rchisq(10000,6)
hist(x, breaks=40)

# normal
hist(rbeta(10000,5,5))

# platykurtic
hist(rt(10000,5), breaks=40)
hist(rnorm(10000,mean=0,sd=5),breaks=40)
hist(c(rnorm(10000,mean=50,sd=10),runif(10000,min=20,max=80)))

```
```{r}
# platycurtic
data=c(rnorm(10000,mean=100,sd=20),runif(10000,min=20,max=170))
hist(data,breaks=30,prob=TRUE)
curve(dnorm(x,mean=mean(data), sd=sd(data)),add=TRUE)
```


```{r}
# leptokurtic
data=c(rnorm(10000,mean=100,sd=20),rnorm(10000,mean=100,sd=5))
hist(data,breaks=30,prob=TRUE)
curve(dnorm(x,mean=mean(data), sd=sd(data)),add=TRUE)

```


```{r}
# simulating positive skewed data

N <- 10000
 x <- rnbinom(N, 8, .5)
 hist(x, 
 xlim=c(min(x),max(x)), probability=T, nclass=max(x)-min(x)+1, 
   col='lightblue', xlab=' ', ylab=' ', axes=F,
   main='Positive Skewed')
lines(density(x,bw=1), col='red', lwd=3)
```

```{r}
# simulate outcome with 2 predictors and significant interaction (2-way ANOVA)

# set total participants
n = 40

# Set coefficients
alpha = 66
beta1 = 1.5
beta2 = 2
beta3 = 2
sde = 2 # standard deviation of the errors (values 1-3 seems to work well)

# Generate 200 trials
A = c(rep(c(0), n/2), rep(c(1), n/2)) # '0' n/2 times, '1' n/2 times
B = rep(c(rep(c(0), n/4), rep(c(1), n/4)), 2) # '0'x n/4, '1'x n/4, '0'x n/4, '1'x n/4
e = rnorm(n, 0, sd=sde) # Random noise, with standard deviation of 1

# Generate your data using the regression equation
y = alpha + beta1*A + beta2*B + beta3*A*B + e

# Join the variables in a data frame
data = data.frame(cbind(A, B, y))

# Fit an ANOVA
model = aov(y ~ A*B, data=data)
summary(model)

modelA = aov(y ~ A, data=data)
summary(modelA)

modelB = aov(y ~ B, data=data)
summary(modelB)
```

