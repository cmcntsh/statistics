---
title: "Week 2 R Assignment - Data exploration and cleaning"
output: html_document

---
## Introduction:
Data needs to be examined and any problems fixed before analysis can be done.In statistics, we focus on four areas.

1. Data accuracy
    + make sure data types are correct
    + check for typos
    + check for nonsensical data
    + check categories make sense
    + correct problems if possible or delete
    + reverse code items if needed
    + score instruments if needed
    + keep track of what you do so you can be transparent
2. Missing data
3. outliers
4. Statistical assumptions

This assignment shows some steps to take to assess data accuracy and identify missing data.

## Directions:
Complete each step of the assignment below.

## 1. Install/Load needed packages
Run the following code block to install the R packages needed for this assignment and load them into memory. (This may take a few minutes if you haven't installed the packages before. If you get any errors or warnings, try running the block another time.)
```{r}
# List the packages needed
packages <- c("tidyverse","summarytools", "labelled", "openxlsx")

# Check if each package is installed already. If not, install the package.
for (i in packages){
  if(! i %in% installed.packages()){
    install.packages(i,dependencies = TRUE)
  }
  # Show each package that is checked.
  print(i)
  
  # Load each package into memory so we can use it.
  library(i,character.only=TRUE)
}
```


1) Data files can be opened using the menus in RStudio or by executing code. Open your data file by using the menu or executing the code block below to open the Week1.csv file. If you use the menus, make sure to select From Text (readr)... (The code below was generated using the menu.) We will use Tidyverse packages as much as possible in this class. The readr package is a Tidyverse package.

```{r}
library(readr)
dataset <- readr::read_csv(file.choose())
View(dataset)
```

2) A great place to start is just taking a look at the data. The three commands in the code block below all let you to take a look at what's in the data set. Uncomment one of the lines and run the code block to see what it does. Replace the comment and try one of the other commands. After you've tried all three type the name and data type for each variable in the spaces below. (The data type is the short segment that comes after the name using the glimpse() or str() function.)
a)
b)
c)
d)
```{r}
#View(dataset)
dplyr::glimpse(dataset) # dplyr is part of the Tidyverse packages
#str(dataset)
```
3) The glimpse() and str() functions give you abbreviations for the data types. Run the code block below to see the data type for the data set and each column.R tries to guess the data type when you import data. It did a good job of identifying numerical variables interval and ratio. Variables with letters in the values get types as character variables.
```{r}
# See column information
dataset %>%
  dplyr::summarise_all(class) %>%
  tidyr::gather(variable, class)

```
4) The readr package doesn't automatically convert columns with strings to factors. We need to convert the nominal and ordinal variables to factors and set the order of the levels for the ordinal variable. (R puts factor levels in alphabetical order if an order is not specified.) If you run #3 again after you execute the following code block, you'll see the class has changed for nominal and ordinal. What are the levels for the two factors (categorical variables) in the data set?
a) nominal - 
b) ordinal - 
```{r}
dataset <- dataset %>% mutate(nominal = as.factor(nominal))
levels(dataset$nominal)
dataset <- dataset %>% mutate(ordinal = as.factor(ordinal))
levels(dataset$ordinal)
# These could have been done on a single line.
# dataset <- dataset %>% mutate_at(vars(nominal, ordinal), factor)
dataset <- dataset %>% mutate(ordinal = fct_relevel(ordinal,"first","second","third","fourth"))
levels(dataset$ordinal)
```
5) Now that all the variables in the dataset have the correct class set (based on level of measurement) we can review each variable to look for other errors. Use the View() function (or just click on the dataset object in the Environment tab to the right) to check over the variables. Do you see any misspellings, unreasonable values, or missing data? If you click on the variable name at the top of the column, RStudio sorts the column. It's really useful for finding really high, low, or missing values. Try it out for each column. Note any problems in a) below.
a)
```{r}
View(dataset)
```


6) After a visual inspection it's a good idea to explore the data using some descriptive statistics. Run the following code block to look at descriptive statistics for the two numeric variables (interval, ratio). List how many valid items exist for each variable. List how many missing items for each variable.
a) interval
b) ratio

Does that match what you see with your visual inspection using View()? (yes or no)
a) 

```{r}
dataset %>%
  dplyr::select(interval,ratio) %>%
  dplyr::summarise_each(funs(class = class
                             , valid = sum(!is.na(.),na.rm = TRUE)
                             , missing = sum(is.na(.))
                             , misspercent = scales::percent(round(sum(is.na(.))/sum(!is.na(.)
                                                                                     ,na.rm = TRUE),2))
                             , min = min(.,na.rm = TRUE)
                             , q25 = quantile(., 0.25,na.rm = TRUE)
                             , median = median(.,na.rm = TRUE)
                             , q75 = quantile(., 0.75,na.rm = TRUE)
                             , max = max(.,na.rm = TRUE)
                             , range = diff(range(.))
                             , mean = round(mean(.,na.rm = TRUE),2)
                             , sd = round(sd(.,na.rm = TRUE),2)
                             , variance = round(var(.,na.rm = TRUE),2)
                             , ShapWilk = ifelse(sd(.)!=0,round(shapiro.test(.)$statistic,2),NA)
                             , ShapWilkp = ifelse(sd(.)!=0,round(shapiro.test(.)$p.value,2),NA))) %>%
  tidyr::gather(stat,val) %>%
  tidyr::separate(stat, into = c("var", "stat"), sep = "_") %>%
  tidyr::spread(stat, val) %>%
  dplyr::select(var
                , class
                , valid
                , missing
                , misspercent
                , min
                , q25
                , median
                , q75
                , max
                , range
                , mean
                , sd
                , variance
                , ShapWilk
                , ShapWilkp) %>% # reorder
  print()
```
7) Here's a similar code blook looking at some descriptive statistics for the factor variables. (nominal, ordinal).
```{r}
dataset %>%
  dplyr::select(nominal, ordinal) %>%
  dplyr::summarise_each(funs(class = class
                             , valid = sum(!is.na(.),na.rm = TRUE)
                             , missing = sum(is.na(.))
                             , misspercent = scales::percent(round(sum(is.na(.))/sum(!is.na(.)
                                                                                     ,na.rm = TRUE),2))
                             , cats = n_distinct)) %>%
  tidyr::gather(stat,val) %>%
  tidyr::separate(stat, into = c("var", "stat"), sep = "_") %>%
  tidyr::spread(stat, val) %>%
  dplyr::select(var
                , class
                , valid
                , missing
                , misspercent
                , cats) %>% # reorder
  print()
```
8) Here's some code to calculate descriptive statistics for the nominal factor.
```{r}
# https://beta.rstudioconnect.com/content/3350/dplyr_tutorial.html
dataset %>%
    dplyr::group_by(nominal) %>%
    dplyr::summarize(frequency = n()) %>%
    dplyr::arrange(desc(frequency)) %>%
    dplyr::mutate(relative_frequency = frequency/sum(frequency),
           relative_cumulative_frequency = cumsum(relative_frequency),
           relative_frequency = round(100*relative_frequency,2),
           relative_cumulative_frequency = round(100*relative_cumulative_frequency,2),
           nr = row_number(-frequency)) %>%
    dplyr::select(nr, everything())
```
9) Using functions from the dplyr package allows you a lot of control over what you can see in your data. I didn't find any Tidyverse packages which report common descriptive statistics without manually coding the desired functions. From this point out, we'll use another package called summarytools to get most of our descriptive statistics. The freq() function is what you should use for categorical variables (factors) like nominal and ordinal. Run the following code block.
```{r}
# https://cran.r-project.org/web/packages/AMR/vignettes/freq.html
summarytools::freq(dataset[c("nominal","ordinal")])
```
10) The descr() function is what you should use for continuous variables (numeric) like interval and ratio. Run the following code block.
```{r}
summarytools::descr(dataset[c("interval","ratio")])
```
11) The summarytools packages also has a function for getting a quick overview of an entire data set. Run the following code block. you should see a new item appear in the Viewer window to the right in RStudio.
```{r}
# https://cran.r-project.org/web/packages/summarytools/vignettes/Introduction.html
#view(dfSummary(dataset, plain.ascii = FALSE, style = "grid", 
#          graph.magnif = 0.75, valid.col = FALSE, tmp.img.dir = "/tmp"))
view(dfSummary(dataset))
```
12) Plots should also be used to explore your data while data cleaning. Run the following code blocks to see examples of plots for each variable type.
```{r}
ggplot(data=dataset, aes(x=nominal)) + 
  geom_bar(stat="count")
```
```{r}
ggplot(data=dataset, aes(x=ordinal)) +
  geom_bar(aes(y = (..count..)/sum(..count..)))
```
```{r}
ggplot(data=dataset, aes(x= "", y = interval)) +
  geom_boxplot()
```
```{r}
ggplot(data=dataset, aes(x=ratio)) +
  geom_histogram(binwidth = .2)
```
```{r}
ggplot(data=dataset, aes(x=interval, y=ratio)) + 
  geom_point()
```

13) The ggplot2 function qplot() is a quick way to make plots. Run the following block of code to create plots for all the variables using qplot(). Answer the following question. (Type your answer below.) What are advantages/disadvantages to using qplot?
a) Advantages - 
b) Disadvantages - 
```{r}
qplot(dataset$nominal)
qplot(dataset$ordinal)
qplot(dataset$interval)
qplot(dataset$ratio)
qplot(dataset$nominal,dataset$ratio)
```

14) You can export your data set to a csv file. Save your data by running the following code block. After you run the code block, navigate to the folder and make sure the new file has been saved.Saving to a csv only saves the variables and the data. It does not save changes we made like converting the nominal and ordinal variables to factors.
```{r}
readr::write_csv(dataset, path = "Week2data.csv")
```

15) You can export data objects to another format which preserves formatting. The csv file is useful for exporting data which can be opened by other programs like Excel and SPSS.The rds file should be used when you know you will use the data in R and you want to preserve the formatting. You can save data in formats for some other statistical software like SPSS. Run the following code block to save the data set as in rds file and an SPSS sav file.
```{r}
# Example of how to save several formats.
readr::write_rds(dataset, path = "week2data.rds")
haven::write_sav(dataset, path = "week2data.sav")
openxlsx::write.xlsx(dataset, file = "week2data.xlsx")

```



16) Save this assignment as an Rmd file by using the RStudio menus. RStudio - File - Save As... Name the file Week2completedYourName. Turn in your Rmd file and your rds file you just saved.